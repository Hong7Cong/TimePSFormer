{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "colnames=['video_id', 'middle_frame_timestamp', 'x1', 'x2', 'y1', 'y2', 'action_id', 'person_id'] \n",
    "kinetics_train = pd.read_csv('/data1/hongn/ava_kinetics_v1_0/kinetics_train_v1.0.csv', names=colnames, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136842"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kinetics_train['video_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiddle_frame_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m      3\u001b[0m val_ava \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data1/hongn/ava_kinetics_v1_0/ava_val_v2.2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, names\u001b[38;5;241m=\u001b[39mcolnames, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "colnames=['video_id', 'middle_frame_timestamp', 'x1', 'x2', 'y1', 'y2', 'action_id', 'person_id'] \n",
    "val_ava = pd.read_csv('/data1/hongn/ava_kinetics_v1_0/ava_val_v2.2.csv', names=colnames, header=None).dropna()\n",
    "val_ava.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/hongn/miniconda3/envs/moose/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from timesformer.datasets.ava import Ava\n",
    "from timesformer.utils.parser import load_config\n",
    "\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cfg_file', help=\"restore checkpoint\")\n",
    "parser.add_argument('--opts', help=\"restore checkpoint\")\n",
    "args = parser.parse_args(['--cfg_file', \"/data2/hongn/TimePSFormer/configs/Kinetics/SLOWFAST_8x8_R101.yaml\"]) \n",
    "cfg = load_config(args)\n",
    "\n",
    "dataset = Ava(cfg, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, label_arrs, idx, _, extra_data = dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 400)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_arrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSv2 Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "ssv2_dir = glob.glob('/data1/hongn/SSv2/frames/*')\n",
    "list_empty_folder = []\n",
    "for path in ssv2_dir:\n",
    "    if len(os.listdir(path)) == 0:\n",
    "        list_empty_folder.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data1/hongn/SSv2/frames/123178', '/data1/hongn/SSv2/frames/123156']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['/data1/hongn/SSv2/frames/123178', '/data1/hongn/SSv2/frames/123156']\n",
    "list_empty_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TimeSFormer AVA lavel, turn out, it does not need to be processed\n",
    "import pandas as pd\n",
    "val = pd.read_csv('/data1/hongn/SSv2/labels/val.csv')\n",
    "col_merge = 'original_vido_id video_id frame_id path labels'\n",
    "val[col_merge.split(' ')] = val[col_merge].str.split(' ', expand=True)\n",
    "val = val.drop(col_merge, axis=1)\n",
    "# val.to_csv('/data1/hongn/SSv2/labels/train.csv', index=False, header=True)\n",
    "# val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3018451/3018451 [01:19<00:00, 37919.14it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "list_empty_folder = []\n",
    "\n",
    "for name in tqdm(val.path):\n",
    "    if(os.path.isfile('/data1/hongn/SSv2/frames/' + name) == False):\n",
    "        list_empty_folder.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_empty_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_redo = [name.split('/')[0] for name in list_empty_folder]\n",
    "set(folder_redo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAA500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>/data1/hongn/kinetics-dataset/k400/train/8mbN0ubh0q8_000000_000010.mp4</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data1/hongn/kinetics-dataset/k400/train/9bfc-...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data1/hongn/kinetics-dataset/k400/train/VV0KA...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data1/hongn/kinetics-dataset/k400/train/sWCnx...</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data1/hongn/kinetics-dataset/k400/train/Am6c9...</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data1/hongn/kinetics-dataset/k400/train/pC1hX...</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  /data1/hongn/kinetics-dataset/k400/train/8mbN0ubh0q8_000000_000010.mp4  101\n",
       "0  /data1/hongn/kinetics-dataset/k400/train/9bfc-...                       17\n",
       "1  /data1/hongn/kinetics-dataset/k400/train/VV0KA...                      167\n",
       "2  /data1/hongn/kinetics-dataset/k400/train/sWCnx...                      318\n",
       "3  /data1/hongn/kinetics-dataset/k400/train/Am6c9...                      356\n",
       "4  /data1/hongn/kinetics-dataset/k400/train/pC1hX...                      231"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('/data1/hongn/kinetics-dataset/k400/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>https://www.youtube.com/watch?v=Uo_sDYOvW98</th>\n",
       "      <th>113.19</th>\n",
       "      <th>116.11</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=79s5BD0301o</td>\n",
       "      <td>348.50</td>\n",
       "      <td>351.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/watch?v=1syox_mjE6s</td>\n",
       "      <td>124.41</td>\n",
       "      <td>127.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.youtube.com/watch?v=OnV0XbwSAAM</td>\n",
       "      <td>423.48</td>\n",
       "      <td>426.39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.youtube.com/watch?v=Xp83UFuKxyE</td>\n",
       "      <td>616.31</td>\n",
       "      <td>619.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.youtube.com/watch?v=-iDBPhSc2mU</td>\n",
       "      <td>130.50</td>\n",
       "      <td>133.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   https://www.youtube.com/watch?v=Uo_sDYOvW98  113.19  116.11  1  1.1\n",
       "0  https://www.youtube.com/watch?v=79s5BD0301o  348.50  351.50  1    1\n",
       "1  https://www.youtube.com/watch?v=1syox_mjE6s  124.41  127.13  0    1\n",
       "2  https://www.youtube.com/watch?v=OnV0XbwSAAM  423.48  426.39  0    2\n",
       "3  https://www.youtube.com/watch?v=Xp83UFuKxyE  616.31  619.07  1    1\n",
       "4  https://www.youtube.com/watch?v=-iDBPhSc2mU  130.50  133.15  0    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_haa500 = pd.read_csv('/data1/hongn/haa500/raw/climb_icecliff.txt')\n",
    "train_haa500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "action_folders = glob('/data1/hongn/haa500/video/*')\n",
    "label_nameidx_map = pd.DataFrame(columns=['label_name', 'label_index'])\n",
    "# all_data = pd.DataFrame(columns=['paths', 'labels'])\n",
    "# actions\n",
    "action_paths = []\n",
    "labels = []\n",
    "for i in range(len(action_folders)):\n",
    "    action_name = action_folders[i].split('/')[-1]\n",
    "    # print(action_name)\n",
    "    label_nameidx_map.loc[i] = [action_name, i]\n",
    "    actioni_paths = glob(f'/data1/hongn/haa500/video/{action_name}/*')\n",
    "    action_paths.append(actioni_paths)\n",
    "    labels.append(np.ones(len(actioni_paths)) * i)\n",
    "\n",
    "action_paths = np.array(action_paths).flatten()\n",
    "labels = np.array(labels).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(action_paths, labels, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(np.stack([X_train, y_train], axis=1), columns=['paths', 'labels'])\n",
    "val = pd.DataFrame(np.stack([X_val, y_val], axis=1), columns=['paths', 'labels'])\n",
    "test = pd.DataFrame(np.stack([X_test, y_test], axis=1), columns=['paths', 'labels'])\n",
    "\n",
    "label_nameidx_map.to_csv('/data1/hongn/haa500/label_nameidx_map.csv',index=False, header=False)\n",
    "train.to_csv('/data1/hongn/haa500/train.csv',index=False, header=False)\n",
    "val.to_csv('/data1/hongn/haa500/val.csv',index=False, header=False)\n",
    "test.to_csv('/data1/hongn/haa500/test.csv',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['/data1/hongn/haa500/video/basketball_shoot/basketball_shoot_007.mp4',\n",
       "        '121'],\n",
       "       ['/data1/hongn/haa500/video/washing_dishes/washing_dishes_000.mp4',\n",
       "        '297'],\n",
       "       ['/data1/hongn/haa500/video/snowboard_jump/snowboard_jump_010.mp4',\n",
       "        '159'],\n",
       "       ...,\n",
       "       ['/data1/hongn/haa500/video/one_arm_push_up/one_arm_push_up_015.mp4',\n",
       "        '155'],\n",
       "       ['/data1/hongn/haa500/video/sprint_run/sprint_run_006.mp4', '395'],\n",
       "       ['/data1/hongn/haa500/video/frisbee_catch/frisbee_catch_014.mp4',\n",
       "        '432']], dtype='<U109')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121, 297, 159, ..., 155, 395, 432])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 499, 499, 499])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([499., 499., 499., 499., 499., 499., 499., 499., 499., 499., 499.,\n",
       "       499., 499., 499., 499., 499., 499., 499., 499., 499.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "actioni = glob('/data1/hongn/haa500/video/gym_plank/*')\n",
    "len(actioni)\n",
    "np.ones(len(actioni)) * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (20, 2) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m temp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([actioni, np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(actioni))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_data,\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m all_data\n",
      "File \u001b[0;32m/data2/hongn/miniconda3/envs/sapiens_lite/lib/python3.10/site-packages/pandas/core/series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/data2/hongn/miniconda3/envs/sapiens_lite/lib/python3.10/site-packages/pandas/core/construction.py:659\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[1;32m    657\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 659\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m/data2/hongn/miniconda3/envs/sapiens_lite/lib/python3.10/site-packages/pandas/core/construction.py:718\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    720\u001b[0m     )\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (20, 2) instead"
     ]
    }
   ],
   "source": [
    "all_data = pd.DataFrame(columns=['paths', 'labels'])\n",
    "temp = np.stack([actioni, np.ones(len(actioni))], axis=1)\n",
    "all_data = pd.concat([all_data,pd.Series(temp)], ignore_index=True)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data1/hongn/haa500/raw/play_ukulele.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
